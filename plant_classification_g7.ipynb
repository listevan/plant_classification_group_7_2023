{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbe5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch and numpy and pretrained model\n",
    "from torchvision import models\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# load pretrained model\n",
    "pretrained_model = models.resnet50(weights = 'DEFAULT', progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262de170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes fully connected/classifier layer to new layer for us to train, 15 is the number of solutions or types of leaves\n",
    "pretrained_model.fc = torch.nn.Linear(2048, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a04fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Currently not in use, for if we wanna custom build a softmax but idk how to train it\n",
    "# import torch.nn as nn\n",
    "# # build custom softmax module\n",
    "# class Softmax(nn.Module):\n",
    "#     def __init__(self, n_inputs, n_outputs):\n",
    "#         super().__init__()\n",
    "#         self.linear = nn.Linear(n_inputs, n_outputs)\n",
    " \n",
    "#     def forward(self, x):\n",
    "#         pred = self.linear(x)\n",
    "#         return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d631a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Currently not in use\n",
    "# # adds softmax to model\n",
    "# class MyModel(nn.Module):\n",
    "#     def __init__(self, pretrained_model):\n",
    "#         super(MyModel, self).__init__()\n",
    "#         self.pretrained_model = pretrained_model\n",
    "#         self.last_layer = Softmax(1000, n) # add how many nodes as input and output\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.last_layer(self.pretrained_model(x))\n",
    "\n",
    "# model = MyModel(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c430901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze model except fc layer because we don't wanna retrain the pretrained model\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in pretrained_model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2e32582",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() #could write this out ourselves\n",
    "# need to find an optimizer or make one for a custom softmax function\n",
    "optimizer = torch.optim.SGD(pretrained_model.fc.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3530c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenli/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data_dir = \"/Users/stevenli/SigAida/data/images/\" #change to data directory\n",
    "\n",
    "# gets the label based on the number\n",
    "def getLabel(s):\n",
    "    labels = {1 : 'Ulmus carpinifolia', \n",
    "                2 : 'Acer', \n",
    "                3 : 'Salix aurita', \n",
    "                4 : 'Quercus', \n",
    "                5 : 'Alnus incan', \n",
    "                6 : 'Betula pubescens', \n",
    "                7 : 'Salix alba \\'Sericea\\'', \n",
    "                8 : 'Populus tremula', \n",
    "                9 : 'Ulmus glabra', \n",
    "                10 : 'Sorbus aucuparia', \n",
    "                11 : 'Salix sinerea', \n",
    "                12 : 'Populus', \n",
    "                13 : 'Tilia', \n",
    "                14 : 'Sorbus intermedia', \n",
    "                15 : 'Fagus silvatica'}\n",
    "    return labels.get(int(s))\n",
    "\n",
    "im = [] # images\n",
    "la = [] # labels not in use, because you can't feed strings to gpu, need to feed tensors\n",
    "ohe = [] #s toring int values for one hot encodings\n",
    "joined = []\n",
    "\n",
    "for f in os.listdir(data_dir):\n",
    "    im.append(data_dir + f)\n",
    "    val = int(f[:-9].replace('l','')) # removes last 9 letters replaces l with blank then gets label\n",
    "    la.append(getLabel(val)) \n",
    "    ohe.append(val)\n",
    "\n",
    "#one hot encoding (changing 1-15 to tensors for gpu)\n",
    "encoded = OneHotEncoder(categories = [[x for x in range(1, 16)]], sparse = False).fit_transform(np.array(ohe).reshape((len(ohe),1)))\n",
    "# print(encoded)\n",
    "\n",
    "#joining image and label for organization and if we wanna shuffle\n",
    "for image, label in zip(im, encoded):\n",
    "    joined.append([image, label])\n",
    "\n",
    "# print(la)\n",
    "# print(im)\n",
    "# print(joined[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2c21ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125\n",
      "900\n",
      "112\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "# some preprocessing, randomize data, split data, load into dataloaders\n",
    "import random\n",
    "\n",
    "# splits (train, val, test) test currently not in use\n",
    "split_ratio=(0.8, 0.1, 0.1)\n",
    "\n",
    "def create_splits(data, split_ratio):\n",
    "    random.shuffle(data)\n",
    "    train = [data[i] for i in range(0, round(.8 * len(data)))]\n",
    "    val = [data[i] for i in range(round(.8 * len(data)), round(.9 * len(data)))]\n",
    "    test = [data[i] for i in range(round(.9 * len(data)), len(data))]\n",
    "    return train, val, test\n",
    "\n",
    "train, val, test = create_splits(joined, split_ratio)\n",
    "\n",
    "print(len(joined))\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f5b89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# makes a custom dataset based on pytorch dataset class\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, data_dir, arr, transform = None):\n",
    "        # initialize some valuess\n",
    "        self.data_dir = data_dir\n",
    "        self.data = [x[0] for x in arr]\n",
    "        self.arr = arr\n",
    "\n",
    "        #transform to normalize/resize all images\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.arr)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.transform(Image.open(self.arr[idx][0]))\n",
    "        s = self.arr[idx][1]\n",
    "        #returns a tuple of the transformed image and the label (one-hot encoding)\n",
    "        return (img, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7556e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "#defining our transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224), # change to what data should be\n",
    "    transforms.CenterCrop(224), # trying what happens if no center crop cuz it cuts off larger images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#making dataset and dataloader (gives data to model, using batch_size 1 cuz google says that's good for sgd (stochastic gradient descent))\n",
    "train_dataset = PlantDataset(data_dir, train, transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8160eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#chcek devices change to whatever you're using\n",
    "\n",
    "#mps = (m1/m2 mac) gpu\n",
    "\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "971f44ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:59<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.8369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:58<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.7691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [04:55<00:00,  3.05it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.6604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:00<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [09:10<00:00,  1.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.7411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:59<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.3939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [04:06<00:00,  3.66it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.6762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:58<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.7321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [02:20<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.3207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:58<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:59<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:01<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:58<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.4152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:01<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:59<00:00, 15.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.2546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:00<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [08:47<00:00,  1.71it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.3188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:59<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.6566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:59<00:00, 15.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.5138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:46<00:00,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.2486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # progress\n",
    "\n",
    "#set device\n",
    "device = torch.device('mps')\n",
    "\n",
    "# Train the model\n",
    "pretrained_model.train()\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data, label in tqdm(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        pretrained_model.to(device)\n",
    "        images = data.to(device)\n",
    "        labels = label.float().to(device) #.float() for some float64, float32 conversion thing, don't completely understand\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = pretrained_model(images) #currently image tensor don't match fc layer if you use non pretrained model\n",
    "        loss = criterion(outputs, labels) #calculate loss\n",
    "\n",
    "        # Backward and optimize don't really understand this stuff\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print some statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4270f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:50<00:00, 17.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy on test dataset\n",
    "total_correct = 0\n",
    "total_instances = 0\n",
    "\n",
    "pretrained_model.eval()\n",
    "# iterating through batches without updating gradients\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(train_loader):\n",
    "      images = images.to(device)\n",
    "      # labels = labels.float().to(device) # don't need this cuz we not training no more\n",
    "\n",
    "      # making classifications and deriving indices of maximum value via argmax (which gives the max value i the tensor)\n",
    "      solution_tensor = pretrained_model(images)\n",
    "      classifications = torch.argmax(solution_tensor, dim = 1).item()\n",
    "\n",
    "      #undoing one-hot encoding to get label value as a number\n",
    "      label = np.where(labels.numpy() == 1)[1]\n",
    "\n",
    "      correct_predictions = int(classifications==label)\n",
    "\n",
    "      #  incrementing counters\n",
    "      total_correct+=correct_predictions\n",
    "      total_instances+=len(images)\n",
    "\n",
    "#print accuracy\n",
    "print(round(total_correct/total_instances, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b99bea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading validation dataset\n",
    "val_dataset = PlantDataset(data_dir, val, transform = transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57f9f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:07<00:00, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_instances = 0\n",
    "\n",
    "pretrained_model.eval()\n",
    "# iterating through batches without updating gradients\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader):\n",
    "      images = images.to(device)\n",
    "      # labels = labels.float().to(device) # don't need this cuz we not training no more\n",
    "\n",
    "      # making classifications and deriving indices of maximum value via argmax (which gives the max value i the tensor)\n",
    "      solution_tensor = pretrained_model(images)\n",
    "      classifications = torch.argmax(solution_tensor, dim = 1).item()\n",
    "\n",
    "      #undoing one-hot encoding to get label value as a number\n",
    "      label = np.where(labels.numpy() == 1)[1]\n",
    "\n",
    "      correct_predictions = int(classifications==label)\n",
    "\n",
    "      #  incrementing counters\n",
    "      total_correct+=correct_predictions\n",
    "      total_instances+=len(images)\n",
    "\n",
    "#print accuracy\n",
    "print(round(total_correct/total_instances, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a7c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test dataset\n",
    "test_dataset = PlantDataset(data_dir, test, transform = transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "619d11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:06<00:00, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_instances = 0\n",
    "\n",
    "pictures = []\n",
    "model_guesses = []\n",
    "correct_answers = []\n",
    "\n",
    "# iterating through batches without updating gradients\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "      pictures.append(images)\n",
    "      images = images.to(device)\n",
    "\n",
    "      # making classifications and deriving indices of maximum value via argmax (which gives the max value i the tensor)\n",
    "      solution_tensor = pretrained_model(images)\n",
    "      classifications = torch.argmax(solution_tensor, dim = 1).item()\n",
    "      model_guesses.append(getLabel(classifications + 1)) # + 1 to convert from index to dict key\n",
    "\n",
    "      #undoing one-hot encoding to get label value as a number\n",
    "      label = np.where(labels.numpy() == 1)[1]\n",
    "      correct_answers.append(getLabel(label + 1)) # + 1 to convert from index to dict key\n",
    "\n",
    "      correct_predictions = int(classifications==label)\n",
    "\n",
    "      #  incrementing counters\n",
    "      total_correct+=correct_predictions\n",
    "      total_instances+=len(images)\n",
    "\n",
    "#print accuracy\n",
    "print(round(total_correct/total_instances, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36b79b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our classifiction is:  Ulmus glabra  and the correct classification is  Betula pubescens\n",
      "Our classifiction is:  Salix alba 'Sericea'  and the correct classification is  Ulmus glabra\n",
      "Our classifiction is:  Populus tremula  and the correct classification is  Populus tremula\n"
     ]
    }
   ],
   "source": [
    "test_indices = [random.randint(0, len(pictures)) for x in range(3)] # 3 is arbitray choose as many as you wanna show\n",
    "transform = transforms.ToPILImage()\n",
    "for test in test_indices:\n",
    "    img = transform(torch.reshape(pictures[test], (3, 224, 224)))\n",
    "    img.show()\n",
    "    print('Our classifiction is: ', model_guesses[test], ' and the correct classification is ', correct_answers[test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
